{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11370047,"sourceType":"datasetVersion","datasetId":7117656},{"sourceId":11383870,"sourceType":"datasetVersion","datasetId":7128105}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:15:01.491309Z","iopub.execute_input":"2025-04-13T04:15:01.491770Z","iopub.status.idle":"2025-04-13T04:15:01.841075Z","shell.execute_reply.started":"2025-04-13T04:15:01.491735Z","shell.execute_reply":"2025-04-13T04:15:01.840065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üîç Overview\n\nThe AI Study Buddy is a personalized learning assistant that leverages Google‚Äôs Gemini Flash 2.0 API, embeddings, and FAISS vector search to provide evidence-based, multilingual, and context-aware academic support. This assistant extracts knowledge from uploaded PDF study guides and provides intelligent, summarized responses to user queries ‚Äî making learning interactive and efficient.","metadata":{}},{"cell_type":"markdown","source":"# **üß± Project Architecture**\n\n* üóÇÔ∏è Data Ingestion: PDF + web documents + notes\n  \n* üß¨ Embeddings: Convert content to vector form\n\n* üî§ Translation Utilities : Translates the input text into a specified target language\n\n* üß† LLM Integration: Query + reasoning\n\n* üåê Multilingual Support: EN/FR/HI/ES/AR using Gemini Flash 2.0\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# üß™ Setup & Environment\n\n# 1. üîß Environment Setup\nTo ensure smooth execution within the Kaggle Notebook environment:\n\n* Required libraries such as google-generativeai, faiss-cpu, PyPDF2, langdetect, and deep-translator are installed.\n\n* kaggle_secrets is used to securely load the Gemini API key from the notebook environment.","metadata":{}},{"cell_type":"code","source":"!pip install -q google-generativeai faiss-cpu PyPDF2 langdetect deep-translator\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:15:01.842548Z","iopub.execute_input":"2025-04-13T04:15:01.842943Z","iopub.status.idle":"2025-04-13T04:15:12.122762Z","shell.execute_reply.started":"2025-04-13T04:15:01.842921Z","shell.execute_reply":"2025-04-13T04:15:12.121853Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport faiss\nimport PyPDF2\nimport numpy as np\nimport google.generativeai as genai\nfrom langdetect import detect\nfrom deep_translator import GoogleTranslator\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom google.colab import userdata  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:15:12.124053Z","iopub.execute_input":"2025-04-13T04:15:12.124415Z","iopub.status.idle":"2025-04-13T04:15:15.955280Z","shell.execute_reply.started":"2025-04-13T04:15:12.124382Z","shell.execute_reply":"2025-04-13T04:15:15.954426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üîë API Key Setup","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\ngenai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n\nmodel = genai.GenerativeModel(\"gemini-2.0-flash\")  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:15:15.956099Z","iopub.execute_input":"2025-04-13T04:15:15.956646Z","iopub.status.idle":"2025-04-13T04:15:16.026488Z","shell.execute_reply.started":"2025-04-13T04:15:15.956597Z","shell.execute_reply":"2025-04-13T04:15:16.025667Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. üìÑ PDF Document Parsing\n\nUploaded study material (e.g., Machine learning mastery) is parsed using PyPDF2:\n\n* The extracted raw text is cleaned and segmented into chunks of ~1000 characters.\n\n* These chunks act as semantic units for embedding and search operations.\n\nThis allows the AI to work with large documents effectively while maintaining response accuracy.","metadata":{}},{"cell_type":"code","source":"#Add files as pdf path\npdf_path = \"/kaggle/input/machine-learning-algorithms/machine_learning_algorithms_from_scratch_sample.pdf\"\npdf_path = \"/kaggle/input/machine-learning-mastery-for-engineers/MachineLearningMasteryforEngineers.pdf\"\n\ndef extract_text_from_pdf(file_path):\n    text = \"\"\n    with open(file_path, \"rb\") as file:\n        reader = PyPDF2.PdfReader(file)\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\nraw_text = extract_text_from_pdf(pdf_path)\nprint(\"‚úÖ PDF loaded. Length of text:\", len(raw_text))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:22:55.872008Z","iopub.execute_input":"2025-04-13T04:22:55.872903Z","iopub.status.idle":"2025-04-13T04:22:59.100041Z","shell.execute_reply.started":"2025-04-13T04:22:55.872870Z","shell.execute_reply":"2025-04-13T04:22:59.099257Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. üìö Split Text into Overlapping Chunks\n\n* üîπ Splits large text into smaller chunks.\n\n* ‚úÇÔ∏è Each chunk has a fixed **chunk_size** (default: 1000).\n\n* üîÅ Overlaps chunks by **overlap** characters (default: 200).\n\n* üì§ Returns a list of overlapping text segments.","metadata":{}},{"cell_type":"code","source":"def chunk_text(text, chunk_size=1000, overlap=200):\n    chunks = []\n    start = 0\n    while start < len(text):\n        end = start + chunk_size\n        chunks.append(text[start:end])\n        start = end - overlap\n    return chunks\n\nchunks = chunk_text(raw_text)\nprint(\"‚úÖ Total Chunks:\", len(chunks))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:23:03.251483Z","iopub.execute_input":"2025-04-13T04:23:03.251894Z","iopub.status.idle":"2025-04-13T04:23:03.259790Z","shell.execute_reply.started":"2025-04-13T04:23:03.251868Z","shell.execute_reply":"2025-04-13T04:23:03.258602Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üß† 4. Generate Embeddings + Vector Indexing (FAISS)\n\n* üß† **embed_text():** Converts text to 768D embeddings using Gemini.\n\n* üì¶ **create_faiss_index():** Builds FAISS index and stores all chunk embeddings.\n\n* ‚ö° Enables fast semantic search over document chunks.","metadata":{}},{"cell_type":"code","source":"\n# Embed a single chunk of text using Gemini\ndef embed_text(text):\n    response = genai.embed_content(\n        model=\"models/embedding-001\",\n        content=text,\n        task_type=\"retrieval_document\"\n    )\n    embedding = response[\"embedding\"]\n    return np.array(embedding, dtype=np.float32).reshape(1, -1)\n\n# Create FAISS index from all text chunks\ndef create_faiss_index(chunks):\n    dim = 768  # Gemini embedding size\n    index = faiss.IndexFlatL2(dim)\n    embeddings = []\n\n    for chunk in chunks:\n        emb = embed_text(chunk)\n        index.add(emb)\n        embeddings.append(emb)\n\n    return index, np.vstack(embeddings)\n\n# Run it\nfaiss_index, chunk_embeddings = create_faiss_index(chunks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:23:06.023113Z","iopub.execute_input":"2025-04-13T04:23:06.023717Z","iopub.status.idle":"2025-04-13T04:24:17.311148Z","shell.execute_reply.started":"2025-04-13T04:23:06.023687Z","shell.execute_reply":"2025-04-13T04:24:17.310172Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. üåêüî§ Translation Utilities \n\nThis code provides basic language detection and translation features:\n\n* Initializes a translation object using googletrans.\n\n* Detects the language of a given text using langdetect.\n\n* Translates the input text into a specified target language using Google Translate.\n\n","metadata":{}},{"cell_type":"code","source":"def detect_language(text):\n    return detect(text)\n\ndef translate_text(text, target_lang):\n    return GoogleTranslator(source='auto', target=target_lang).translate(text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:25:43.646674Z","iopub.execute_input":"2025-04-13T04:25:43.647303Z","iopub.status.idle":"2025-04-13T04:25:43.651652Z","shell.execute_reply.started":"2025-04-13T04:25:43.647278Z","shell.execute_reply":"2025-04-13T04:25:43.650816Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. üß†üîé Semantic Search + Answering with Gemini ‚ú®\n\nThis code performs semantic search and generates answers using Gemini:\n\n* Finds the top k most relevant text chunks to the user's query using FAISS similarity search.\n\n* Builds a context-aware prompt with the retrieved chunks and sends it to the Gemini model to generate an informed answer.\n\n‚úÖ Enables intelligent Q&A by combining retrieval with LLM reasoning.","metadata":{}},{"cell_type":"code","source":"def search_similar_chunks(query, chunks, index, chunk_embeddings, k=3):\n    query_vector = embed_text(query)\n    D, I = index.search(query_vector, k)\n    return [chunks[i] for i in I[0]]\n\ndef generate_gemini_response(query, context_chunks):\n    prompt = \"You are an AI Study Buddy. Answer the question based on the context:\\n\\n\"\n    for i, chunk in enumerate(context_chunks):\n        prompt += f\"[Context {i+1}]: {chunk}\\n\\n\"\n    prompt += f\"Question: {query}\\nAnswer:\"\n    response = model.generate_content(prompt)\n    return response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:25:45.974768Z","iopub.execute_input":"2025-04-13T04:25:45.975068Z","iopub.status.idle":"2025-04-13T04:25:45.980661Z","shell.execute_reply.started":"2025-04-13T04:25:45.975045Z","shell.execute_reply":"2025-04-13T04:25:45.979703Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. üó£Ô∏èüåç Multilingual Question Answering with Gemini \nThis block handles a full question-answering pipeline:\n\n* Step 3: User Input\nPrompts the user to ask a question in any language (English, French, Hindi, Spanish or Arabic).\n\n* Step 4: Language Detection & Translation\nDetects the input language and translates it to English if needed for processing.\n\n* Step 5: Semantic Search + Answer Generation\nUses FAISS to find relevant content chunks and Gemini to generate an answer.\n\n* Step 6: Translate Back\nIf the original question wasn‚Äôt in English, the answer is translated back to the user‚Äôs language.\n\n‚úÖ Delivers intelligent, context-aware answers in multiple languages.","metadata":{}},{"cell_type":"code","source":"# Step 3: Ask a question\nuser_input = \"What are the different types of machine learning?\"\n\n#You can use this on hindi. Use the next command:\n#user_input = \"Machine learning ka konse konse bhag hain?\"\n\n\n# Step 4: Language check and translation\nlang = detect_language(user_input)\n\n# Force default to English if detection is unreliable\nif lang not in [\"en\", \"fr\", \"hi\", \"es\", \"ar\"]:\n    lang = \"en\"\n\ntranslated_input = translate_text(user_input, \"en\") if lang != \"en\" else user_input\n\n# Step 5: Semantic Search and Gemini Answer\ntop_chunks = search_similar_chunks(translated_input, chunks, faiss_index, chunk_embeddings)\nanswer = generate_gemini_response(translated_input, top_chunks)\n\n# Step 6: Translate back to original language if needed\nfinal_answer = translate_text(answer, lang) if lang != \"en\" else answer\n\nprint(\"\\nüí¨ AI Study Buddy says:\\n\", final_answer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T04:27:55.034606Z","iopub.execute_input":"2025-04-13T04:27:55.034955Z","iopub.status.idle":"2025-04-13T04:27:55.882313Z","shell.execute_reply.started":"2025-04-13T04:27:55.034933Z","shell.execute_reply":"2025-04-13T04:27:55.881588Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summary","metadata":{}},{"cell_type":"markdown","source":"# Summary\n\n**üìò AI Study Buddy ‚Äì Smart PDF Question Answering**\n\nAI Study Buddy is an intelligent assistant that helps students interactively learn from study guides in PDF format. It uses Google Gemini's language and embedding models to understand questions in English, French, or Arabic, and answers them contextually based on the uploaded material.\n\nüîç Core Features\n\n* Multilingual support (English, French, Hindi, Spanish, Arabic)\n\n* PDF ingestion + semantic chunking\n\n* Embedding with embedding-001 + FAISS vector search\n\n* Context-aware responses using Gemini Flash 2.0\n\n* Translation handled seamlessly both ways\n\nüì¶ How It Works\n\n* PDF is loaded and chunked.\n\n* Each chunk is embedded and stored in FAISS for semantic search.\n\n* User's question is detected for language and translated to English if needed.\n\n* Relevant chunks are retrieved and passed to Gemini Flash for response generation.\n\n* Final answer is translated back to the original input language.\n\nüí° Perfect for:\n\n* Revising from notes\n\n* Getting answers directly from large PDFs\n\n* Non-English speaking students accessing global content\n\n","metadata":{}}]}